# -*- coding: utf-8 -*-
"""Disease Predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PXeObAZX0326fksaVKEaJ0_xbOWCHSSt
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

!kaggle datasets download -d redwankarimsony/heart-disease-data -p /content/heart-disease-data --unzip

import pandas as pd
df = pd.read_csv('/content/heart-disease-data/heart_disease_uci.csv')

df.head()

print(df.columns)

df.isnull().sum()

numeric_columns = df.select_dtypes(include=['number']).columns
df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())

import matplotlib.pyplot as plt
import seaborn as sns

df[numeric_columns].hist(figsize=(15,10))
plt.tight_layout()
plt.show()

sns.heatmap(df[numeric_columns].corr(), annot=True, cmap='coolwarm')
plt.title('Numeric Feature Correlations')
plt.show()

cat_cols = df.select_dtypes(include=['object']).columns.tolist()
if 'num' in cat_cols:
    cat_cols.remove('num')

x = df.drop('num', axis=1)
y = (df['num'] >0).astype(int) # 0: no disease , 1: a disease

x = pd.get_dummies(x, columns=cat_cols)
print("Final feature columns:", x.columns)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression()
lr_model.fit(x_train, y_train)

from sklearn.metrics import accuracy_score , classification_report

y_pred_lr = lr_model.predict(x_test_scaled)
print("Logistic Regression Accuracy:",accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

"""Accuracy score -75 to 98 is considered to be good

"""

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix (Logistic Regression)')
plt.show()

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(x_train, y_train)
y_pred_rf = rf_model.predict(x_test_scaled)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))

feat_imp = pd.Series(rf_model.feature_importances_, index=x.columns)
feat_imp.nlargest(10).plot(kind='barh')
plt.title('Random Forest Feature Importance')
plt.show()

import joblib
joblib.dump(rf_model, 'heart_rf_model.pkl')

joblib.dump(scaler, 'heart_scaler.pkl')

sample = x.head(1)
sample.to_csv('Heart_user_template.csv', index=False)
print("User Template saved as 'Heart_user_template.csv'")

from google.colab import files
files.upload()

import joblib
import pandas as pd

user_df = pd.read_csv('heart_dataset - heart_dataset.csv.csv')

#Getting columns list from training dataframe
numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
cat_cols = df.select_dtypes(include=['object']).columns.tolist()
bool_cols = df.select_dtypes(include=['bool']).columns.tolist()

#Dropping columns which are extra in user_df than required to avoid user
numeric_cols = [col for col in numeric_cols if col in user_df.columns]
cat_cols = [col for col in cat_cols if col in user_df.columns]
bool_cols = [col for col in bool_cols if col in user_df.columns]

#fill the missing numeric column & cat column
user_df[numeric_cols] = user_df[numeric_cols].fillna(user_df[numeric_cols].mean())

for col in cat_cols:
  user_df[col] = user_df[col].fillna('unknown')

for col in bool_cols:
  user_df[col]=user_df[col].astype(int)

#One-hot encoding cat columns
user_df_encoded=pd.get_dummies(user_df,columns=cat_cols)

#Allign columns
user_df_encoded = user_df_encoded.reindex(columns=x.columns, fill_value=0)

#Scale data
scaler = joblib.load('heart_scaler.pkl')
user_df_scaled = scaler.transform(user_df_encoded)

#Prediction
model = joblib.load('heart_rf_model.pkl')
preds = model.predict(user_df_scaled)
user_df['Heart_Disease_Prediction']=preds

#show result
print(user_df)

